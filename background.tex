\section{Background: A Brief Tour of CompCert}
\label{sec:background}

We begin by briefly reviewing the technical background that informs the rest of the dissertation,
using CompCert as the learning material.  We first explain CompCert's organization
(\Cref{sec:background:organization}), and its correctness statement as well as its closed-simulation
verification method (\Cref{sec:background:correctness}).  To flesh out the details on formal
semantics and compiler verification, we use constant propagation---one of CompCert's
optimizations---as a running example.  Specifically, We review the RTL language on which constant
propagation is performed (\Cref{sec:background:rtl}), how constant propagation works
(\Cref{sec:background:opt}), and how CompCert verifies it (\Cref{sec:background:verification}).
Throughout the section, we keep the presentation semi-formal, abstracting away unnecessary detail to
get across the main ideas.



\subsection{CompCert's Organization}
\label{sec:background:organization}

TODO



\subsection{CompCert's Correctness}
\label{sec:background:correctness}


\paragraph{End-to-End Correctness}

Roughly speaking, the correctness result of CompCert can be understood to assert the following.
Suppose \code{s.c} is a ``source'' file (in C), \code{t.asm} is a ``target'' file (in assembly), and
$\mathcal{C}$ is a verified compiler (represented as a function from C files to assembly files).
\[
\frac{
\mathcal{C}(\mathtt{s.c}) = \mathtt{t.asm} \qquad
s = \mathrm{load}(\mathtt{s.c})\qquad
t = \mathrm{load}(\mathtt{t.asm})}
{\mathrm{Behav}(s) \supseteq \mathrm{Behav}(t)}
\]
If \code{t.asm} is the result of compiling \code{s.c} with $\mathcal{C}$, then executing
\code{t.asm} according to assembly semantics will result in a subset of the behaviors one could
observe from executing \code{s.c} according to C semantics.  (We write
$s = \mathrm{load}(\mathtt{s.c})$ to denote the \emph{machine state} that results from loading
$\mathtt{s.c}$ into memory, $\mathrm{Behav}(s)$ to denote the observable behaviors of the execution
of $s$, and analogously for $t$ and $\mathtt{t.asm}$.)  Hence, we say that \code{t.asm}, the
target-level output of $\mathcal{C}$, \emph{refines} its source-level input, \code{s.c}.


\paragraph{Per-Pass Correctness}

To verify compilation correctness for the compiler $\mathcal{C}$, we verify each pass of
$\mathcal{C}$ independently.  Specifically, for each pass (transformation) $\mathcal{T}$ from
language $L_1$ to $L_2$---where the $L_i$'s may be C, assembly, or some intermediate languages---we
show the following:
\[
\frac{
\mathcal{T}(\mathtt{s.l1}) = \mathtt{t.l2} \qquad
s = \mathrm{load}(\mathtt{s.l1}) \qquad
t = \mathrm{load}(\mathtt{t.l2})
}
{
\mathrm{Behav}(s) \supseteq \mathrm{Behav}(t)
}
\]
That is, given the input \code{s.l1} and output \code{t.l2} of the $\mathcal{T}$ transformation, we
show that the behaviors of \code{t.l2} are contained within those of \code{s.l1}.  Since subset
inclusion is transitive, it easy to see that the proofs of the constituent passes of $\mathcal{C}$
compose to establish the correctness of $\mathcal{C}$ as a whole.


\paragraph{Verifying Per-Pass Correctness}

Now how does one actually prove the verification condition for each individual pass?  The standard
approach taken by CompCert is to use (closed) simulations.  Informally, we will say that a
\emph{simulation} $R$ is a relation between running programs (\ie machine states) in $L_1$ and $L_2$
such that, if $(s,t) \in R$, then the behaviors one observes while stepping through the execution of
$t$ are matched by corresponding observable behaviors in the execution of $s$.  One can think of $R$
as imposing an invariant, which describes (and connects) the possible machine states of the source
and target programs, and which must be maintained as the programs execute.  We leave further details
about simulations until later in the paper; suffice it to say that they satisfy the following
``adequacy'' property:
% , and we show that the machine states arising from
% loading \code{s.l1} and \code{t.l2} belong to this simulation.
\[
\frac{
R~\mbox{is a simulation} \qquad
(s,t)\in R
}{
\mathrm{Behav}(s) \supseteq \mathrm{Behav}(t)
}
\]
Thus, to establish the verification condition for pass $\mathcal{T}$, it suffices to exhibit a
simulation $R$ that relates $\mathrm{load}(\mathtt{s.l1})$ and $\mathrm{load}(\mathtt{t.l2})$.

\textbf{Note:} The verification approach described above, relying on ``backward'' simulations, is
something of an oversimplification of what CompCert actually does.  In fact, to make the proofs more
convenient, CompCert uses a mixture of forward and backward simulations.  We gloss over this point
here because it is orthogonal to our high-level story, but we will return to it in
\Cref{chap:sepcomp}.


\paragraph*{}

Then what does a simulation relation look like?  As an example, we explain the constant propagation
pass in CompCert and its simulation relation, as well as the langauge on which the optimization is
performed.


\subsection{CompCert's RTL Language}
\label{sec:background:rtl}

We start with the syntax and semantics of CompCert's register transfer language (RTL), the
compiler's internal language where constant propagation takes place.  For presentation purposes, we
simplify the language a bit by removing types and other unnecessary details.


\paragraph{Syntax}

% \input{rtl-syntax}
% TODO

The syntax of the CompCert's RTL is given in Figure~\ref{fig:rtl-syntax}.  Programs are just a list
of global declarations, which consist of $(1)$ declarations of external variables and functions
provided by different compilation units, and $(2)$ definitions of variables and functions provided
by the current compilation unit.  For global variable declarations and definitions, we also specify
a (positive) integer number denoting the size of the declared block in bytes.

Function declarations only contain the function signature, which is a list of parameters, but
function definitions additionally contain a list of local registers, the size of their stack frame,
and the code.  The code is essentially a control-flow graph of three-address code: it is represented
as a mapping from node identifiers to instructions, where instructions either
%
do some local computation (\eg write a constant to a register, or perform some arithmetic
computation),
%
load from a memory address, 
%
store to memory,
%
do a comparison,
%
call a function, 
%
or exit the function and return a result. 
%
Each instruction also stores the node identifier(s) of its successor instruction(s).

Throughout we assume that programs satisfy some basic well-formedness properties: there cannot be
multiple definitions for the same global variable, declarations and definitions of the same variable
should have matching signatures, and the parameter and local variable lists for each function do not
have duplicate entries.


\paragraph{Semantics}

% \input{rtl-semdom}
% TODO

We move on to the semantics of RTL.  Figure~\ref{fig:rtl-semdom} defines the necessary semantic
domains.

Memory, $m\in\rtlMem$, is represented as a finite collection of allocation blocks (a mapping from
block identifiers to blocks), each of which is a contiguous portion of memory that may be either
valid to access or already deallocated (freed) and therefore invalid to access.  CompCert values,
$v\in\rtlVal$, can be either 32-bit integers, logical addresses (pairs of a block identifier
together with an offset within the block), or the special $\rtlundef$ value used to represent
uninitialized data.  A global environment, $ge=(g,d)\in\rtlGEnv$, maps each global variable name to
a logical block identifier, and each logical block identifier corresponding to some function's code
to either the corresponding function signature for external functions or the corresponding function
definition for functions defined in the program.

Next, program states can be of three kinds: normal instruction states ($\rtlist$), call states
($\rtlcst$) just before passing control to an invoked function, and return states ($\rtlrst$), just
after returning from an invoked function.  Instruction states store the memory ($m$), the sequence
of parent stack frames ($s$), the definition of the function whose body is currently executed
($\vfd$), the current stack pointer ($sp$), the program counter ($pc$), and the contents of the
local registers ($rs$).  Call states record the memory, the stack, and the function to be called
($\vfds$) with its arguments ($args$).  The function to be called can be either an internal
function, in which case we record its definition, or an external one, in which case we record its
signature.  Return states record just the memory, the stack, and the value that was returned by the
function.  A stack $s$ is a list of stack frames, each of which records the same information as
normal instruction states, except with the addition of a register name $r$ where its return value
should be stored, and minus the memory ($m$) and stack ($s$) components.

The meaning of programs is described by three definitions:
\[
\begin{array}{r@{~~}c@{~~}l}
\rtlgenv &\in& \rtlProg \to \rtlGEnv \\
\rtlload &\in& \rtlProg \pfun \rtlState\\
\estep{} &\in& \powset{\rtlGEnv\times\rtlState\times\rtlEvent\times\rtlState}\\
\end{array}
\]
The first function, $\rtlgenv(\vprg)$, returns the global environment corresponding to the program:
it `allocates' the global variables of the program sequentially in blocks 1, 2, 3, and so on, and
maps the blocks corresponding to function symbols to the relevant function definition or signature.

Similarly, $\rtlload(\vprg)$ returns the initial state obtained by loading a program into memory: it
initializes the memory $m$ with the initial values of the global variables at the appropriate
addresses generated by $\rtlgenv(\vprg)$, and returns a call state, $\rtlcst~m~[\,]~\vfd~[\,]$,
where $\vfd$ is the function definition corresponding to \texttt{main()}.  Loading is a partial
function because it is undefined for programs without a \texttt{main()} function.

% \input{rtl-opsem}
% TODO

The $\estep{}$ relation is a small-step reduction relation describing how program states evolve
during the computation.  For clarity, we write $s \estep{\vevt}_{ge} s'$ instead of
$(ge,s,\vevt,s')\in {\estep{}}$.  The operational semantics for RTL is fairly standard and shown in
Figure~\ref{fig:rtl-opsem}: there is a rule for each of the various basic instructions of the
language.  Starting from normal instruction states, the instruction at the node pointed to by the
program counter is scrutinized ($\vfd@pc$).  Depending on what instruction is there, only one rule
is applicable.  The corresponding rule calculates the new values of the registers, the memory (for
store instructions), and the next program counter.  Calls and returns are treated a bit differently:
they do not directly transition from an instruction state to the next instruction state---they go
through an intermediate call/return state.

In more detail, calling a function (rule \textsc{call}) looks up the function in the global
environment, evaluates its arguments, creates a new stack frame corresponding to the current
instruction state, and transitions to a call state.  From a call state, there are two possible
execution steps.  If the function to be called is internal, \ie we have its function definition
$\vfd\in\rtlFunc$, rule \textsc{internal-call} applies.  It allocates the necessary stack space for
the called function, initializes the parameter registers with the values passed as arguments, sets
the program counter to point to the first node of the called function, and moves to the appropriate
instruction state of the called function.  If the function to be called is external, \ie we have a
function signature $\vfs\in\rtlFSig$, rule \textsc{external-call} goes directly to the return state,
and generates an event $\vevt$ indicating that it called an external function.

Conversely, returning from a function (rule \textsc{return}) evaluates the result to be returned,
deallocates the stack space used by the function, and transitions to the return state.  The only
possible step form a return state (rule \textsc{return2}) then pops the top-most stack frame and
transitions to a normal instruction state thereby restoring the registers, program counter, and
stack pointers of the calling function.


\subsection{CompCert's Constant Propagation}
\label{sec:background:opt}



\subsection{CompCert's Verification of Constant Propagation}
\label{sec:background:verification}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% TeX-command-extra-options: "-shell-escape"
%%% End:
